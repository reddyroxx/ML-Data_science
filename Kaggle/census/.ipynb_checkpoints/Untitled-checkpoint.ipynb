{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input file containing data\n",
    "input_file = 'income_data.txt'\n",
    "\n",
    "# Read the data\n",
    "X = []\n",
    "y = []\n",
    "count_class1 = 0\n",
    "count_class2 = 0\n",
    "max_datapoints = 30000\n",
    "\n",
    "with open(input_file, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        if count_class1 >= max_datapoints and count_class2 >= max_datapoints:\n",
    "            break\n",
    "\n",
    "        if '?' in line:\n",
    "            continue\n",
    "\n",
    "        data = line[:-1].split(', ')\n",
    "\n",
    "        if data[-1] == '<=50K' and count_class1 < max_datapoints:\n",
    "            X.append(data)\n",
    "            count_class1 += 1\n",
    "\n",
    "        if data[-1] == '>50K' and count_class2 < max_datapoints:\n",
    "            X.append(data)\n",
    "            count_class2 += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from input file\n",
    "X = np.array(X)\n",
    "\n",
    "# Convert string data to numerical data\n",
    "label_encoder = [] \n",
    "X_encoded = np.empty(X.shape)\n",
    "for i,item in enumerate(X[0]):\n",
    "    if item.isdigit(): \n",
    "        X_encoded[:, i] = X[:, i]\n",
    "    else:\n",
    "        label_encoder.append(preprocessing.LabelEncoder())\n",
    "        X_encoded[:, i] = label_encoder[-1].fit_transform(X[:, i])\n",
    "\n",
    "#X = X_encoded[:, :-1].astype(int)\n",
    "#y = X_encoded[:, -1].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'1': X_encoded[:, 0], '2': X_encoded[:, 1],'3': X_encoded[:, 2], '4': X_encoded[:, 3],'5': X_encoded[:, 4], '6': X_encoded[:, 5],'7': X_encoded[:, 6], '8': X_encoded[:, 7],'9': X_encoded[:, 8], '10': X_encoded[:, 9],'11': X_encoded[:, 10], '12': X_encoded[:, 11],'13': X_encoded[:, 12], '14': X_encoded[:, 13], '15': X_encoded[:, 14]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values[:, 0:14]\n",
    "Y = df.values[:,14]\n",
    "\n",
    "### Splitting data ###\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.3, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.851033263344016\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.793568350093933\n"
     ]
    }
   ],
   "source": [
    "gnb=GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "y_pred=gnb.predict(X_test)\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
